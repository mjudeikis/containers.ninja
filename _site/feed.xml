<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>Containers Ninja - Everyhting about Containers & Cloud</description>
		<link>/</link>
		<atom:link href="/" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Enterprise Openshift Deployment</title>
				<description>&lt;p&gt;At Red Hat we don’t just do open source and write software. We help our clients adopt good practices, spread open source culture, and adopt technology in the right way.&lt;/p&gt;

&lt;p&gt;This post will explore less technical and more “big picture” concepts. When we (Red Hat Professional Services) come on-site to help to deploy OpenShift (Enterprise-ready Kubernetes distribution) we work with the customer to determine what kind of journey they will experience while onboarding and the challenges they may encounter in the future.&lt;/p&gt;

&lt;p&gt;For this purpose, I created a small MindMap to help visualize most of the dependencies that exist when building highly distributed platform. There is much more to this, and this visualization is being updated even as you read this article, but it’s a good start.&lt;/p&gt;

&lt;p&gt;All dependencies are split into 10 categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Strategy&lt;/li&gt;
  &lt;li&gt;Storage&lt;/li&gt;
  &lt;li&gt;Operations&lt;/li&gt;
  &lt;li&gt;BCR &amp;amp; DR&lt;/li&gt;
  &lt;li&gt;AppDev&lt;/li&gt;
  &lt;li&gt;Security&lt;/li&gt;
  &lt;li&gt;Automation&lt;/li&gt;
  &lt;li&gt;Networks&lt;/li&gt;
  &lt;li&gt;Provisioning&lt;/li&gt;
  &lt;li&gt;External dependencies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these contain multiple sub-areas to consider. So let’s go through them one by one.&lt;/p&gt;

&lt;p&gt;TL:DR: Even if you are familiar with this topic, you may find the MindMap valuable. If you want more, I have provided insights for each and every block. Click to enlarge the image or view at [mindmap][https://github.com/mjudeikis/ocp-mindmap].&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/enterprisedeployment/appcoup-pod-150-150-679x1024.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;1. Strategy&lt;/h4&gt;
&lt;p&gt;Your strategy should be one of the first things you think about before beginning the journey of adopting a new platform. You need to know who will be using this platform you are building. Who are the stakeholders, and finally, who is responsible for it? Determining stakeholders is often the easiest part of building the strategy. Establishing a Community of Practices (CoP) will help create a strategy and directions. A well-thought-out and maintained CoP can help you use the power of your own organization to drive progress towards the “right solution.” Solutions delivered behind closed doors tend to miss what an organization needs.&lt;/p&gt;

&lt;p&gt;One other area where you will need a strategy is “microservices standardization.” Before putting services on the new platform, it is highly recommended to have certain standards defined. The challenge here is that old world standards do not apply in this new world. Trying to “copy paste” something you already know might not work as well as you might expect. Consider doing some research on using CoP.&lt;/p&gt;

&lt;h4&gt;2. Storage&lt;/h4&gt;
&lt;p&gt;Storage, or persistence, is a key consideration to plan for if you want a successful platform. And you don’t just need simple storage but highly-scalable storage. You will need storage for internal platform components like logging, metrics, and the container registry. Some of those might not be required if you chose to go with a different implementation of those the solutions (object storage, messaging based logging) based on where you will be building this. But you will not be able to eliminate the need for storage completely. As soon as we start speaking “persistence” we mean storage. Start thinking about how you will do it, who will provide it for you, and what flavors (SSD, Magnetic, SAN, NAS, etc.) of storage you will have.&lt;/p&gt;

&lt;h4&gt;3. Operations&lt;/h4&gt;
&lt;p&gt;The operations section is very tightly connected to next section of this post. Operations mainly consist of 2 areas: Business as Usual (BAU) and unplanned activities (BCR &amp;amp; DR). I’ll cover the last one separately in the next section.&lt;/p&gt;

&lt;p&gt;BAU operations will consist of things like egress router configurations, platform maintenance, patching, scheduling rules creations, platform management, and proactive reactions to the events happening on the platform. For all this, you will need a very good logging and monitoring stack available. Without those you will be blind; and being blind in a highly distributed system is much much worse than in a “standalone servers” infrastructure because things might go from bad to worse very fast. For example, if you lose capacity, your containers will get rescheduled (assuming you don’t have autoscaling, and even if you do, you might start getting very big bills). Rescheduling in the current configuration = bigger density, which means there is a big chance you will soon get into a rolling failure scenario.&lt;/p&gt;

&lt;p&gt;So defining standard runbooks for your operations, creating dashboards, and making sure you know your environment is one of the most important things when it comes to operations.&lt;/p&gt;

&lt;h4&gt;4. BCR &amp;amp; DR&lt;/h4&gt;
&lt;p&gt;I’ve split Business Continuity &amp;amp; Resilience (BCR) and Disaster Recovery (DR) from operations because it is a very big concern. Even before serving production traffic, I recommended you already know your “failure domains” and how to recover if any of those domains fail. For example, you need a plan for if you lose quorum in your distributed reliable key-value store cluster (etcd in the case of OpenShift/Kubernetes) or know what would happen if an external DNS or storage provider fails. There could be multiple different scenarios, which will be different in different environments. Some of the internal/external dependencies will have less or more mature offerings, depending on which type of organization you are in.&lt;/p&gt;

&lt;h4&gt;5. AppDev&lt;/h4&gt;
&lt;p&gt;You need to think about your developers too. Some organizations forget that the platform will be used mostly by developers. And only developers know how they want to run things in a platform. Despite the fact that you will have a lot of tools already in place, you might want to standardize on patterns and blueprints. For example, you should consider:&lt;/p&gt;

&lt;p&gt;How will application developers monitor their applications and node performance?
How will they do promotion and deployment?
How CI/CD pipelines (existing ones and new ones) will integrate with the platform.
How will you be promoting images from the across the environment?
What about configuration promotion?
And finally, what development tools your developers will be using?
Developer experience is very important. Get this right, and your platform will be used. Get it wrong, and nobody will want to use it.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Automation
This particular area has many relationships to other areas. You will need automation for your applications (CI/CD tools), image testing, promotions, etc. Additionally, your infrastructure should be treated the same as your apps— automation everywhere. For this, you might use configuration management tools or rely only on deployment tools. But if you start building from the beginning with the idea of automation, it will get you where you want to be faster, even if it looks slower in the beginning.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;7. Networking&lt;/h4&gt;
&lt;p&gt;You need to think about how you will be accessing your applications, egress and ingress traffic, and how your load balancers will be configured. Determine if you will run active-passive or active-active, and how you will load balance all your stack. Do you want your containers to be “ the first citizen in the network” or will you rely on SDN abstraction? How will DNS be handled? Do you want to do Mutual SSL all over the place (and do you really really need it)? How big will your cluster be in 2-5 years? How many containers will you run on one node? All these questions will define your network design for the platform.&lt;/p&gt;

&lt;h4&gt;8. Security&lt;/h4&gt;
&lt;p&gt;Despite the fact that the platform was built with security in mind, you still will have a lot of open questions. For example, how you are managing your secrets (passwords, certificates) and how will rotate them? How will you expose your application to the outside world? And finally, and most importantly, how will you validate images you are running? Image scanning and lifecycle is key when running multitenancy, microservice-based applications.&lt;/p&gt;

&lt;h4&gt;9. Provisioning&lt;/h4&gt;
&lt;p&gt;Provisioning is very broad and highly connected to how you do these things in your organization:&lt;/p&gt;

&lt;p&gt;Configuration management: Which one will you use, and how it will play with the tools the platform supports? As soon as you chose one, what tooling comes with it? What additional tools will you need? Will you need Red Hat Satellite for subscription and infra lifecycle management? And CloudForms for insights, capacity, and proactive management? What is the visualization provider and its capabilities?
Infrastructure itself: Do you use containerized deployments or package/RPM-based? How does this connect to your organization patching strategies? For example, if you are a full RPM-based organization, and you chose a containerized/OSTree based platform, will your ops know how to lifecycle those?
And finally, what customization will you need to do for the platform (pre, post actions) to make it compliant and custom for your needs?&lt;/p&gt;

&lt;h4&gt;10. External dependencies&lt;/h4&gt;
&lt;p&gt;You will have a lot of these, so make sure you know how resilient they are and what SLAs they provide. A few external dependencies would be:&lt;/p&gt;

&lt;p&gt;Logging and monitoring: Where do you send your logs for archiving? Do you have any external logging and monitoring solution you need to integrate with? Will you provide metadata too?
Storage: How will you use it? Is it fast enough? What about input/output operations per second (IOPS)? What will happen if it goes down or gets filled?
Container registry: If you plan to run a globally distributed set of clusters, how will you make sure you have a consistent view of your images? Do you have the need to storage container images externally? If so, what format?
Authentication &amp;amp; authorization: How will you authenticate your users and applications? What is the preferred auth provider? How you do your Role Based Access Control (RBAC) based on your auth provider?
ITSM/CMDB: Do you need to register your apps on any configuration management database? How this will be automated (or will an automated solution even work here?). What do you consider a change?&lt;/p&gt;

&lt;h4&gt;11. Architecture&lt;/h4&gt;
&lt;p&gt;The thing which should be one of the first I saved for the last. As soon as you know where you want to go (strategy), you need to start thinking about wider architecture, such as an infrastructure density, datacenters, and availability zones. Most of the areas already covered are associated with the architecture of the platform itself. You need to make the right choices in the beginning, as distributed platforms like Openshift/Kubernetes are hard to modify (the core of it) when it is built and in use by hundreds, or even thousands, of applications. If you get networking wrong it is not impossible to change it later. If you do not accommodate the ability of your external dependencies to scale with your platform, you will create bottlenecks.&lt;/p&gt;

&lt;p&gt;All these are high level points what you need to think about if you chose to go on this journey. And let’s be clear about one thing: Public cloud does not solve all these questions. It’s just a different conversation. It may look hard and not worth it. But the final result—having full-cloud agnostic, horizontally and vertically scalable self-service infrastructure—will make developers happy.&lt;/p&gt;
</description>
				<pubDate>Tue, 15 Aug 2017 00:00:00 +0100</pubDate>
				<link>/openshift/deployment/planning/2017/08/15/enterprise-deployment.html</link>
				<guid isPermaLink="true">/openshift/deployment/planning/2017/08/15/enterprise-deployment.html</guid>
			</item>
		
			<item>
				<title>Patterns for Application Augmentation on OpenShift</title>
				<description>&lt;p&gt;Over the past few years, I’ve seen many different types of application implementations on the OpenShift platform (Red Hat’s &lt;a href=&quot;ttps://www.openshift.com&quot;&gt;Enterprise Distribution of Kubernetes&lt;/a&gt;). There are many pros and cons for using the different methods. But, at this point, there is no common template to recommend for everyone’s use case. This is what makes Infrastructure as Code so interesting.&lt;/p&gt;

&lt;p&gt;In this post, I’ll cover three patterns for integrating monitoring agents with your OpenShift applications. We’ll use a Java application as an example with a New Relic agent as the piece to be integrated with.&lt;/p&gt;

&lt;p&gt;We’ll cover three use cases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Agent is part of the base application container image. We use “all-in-one” images, where the agent’s components are delivered as part of the main image. This is the most common use case I see. Why? Because at the time when people started adopting OpenShift, this was the only way to achieve their goal, and this practice has continued. It makes sense for some cases, but with the current capabilities provided by the platform, many improvements are possible.&lt;/li&gt;
  &lt;li&gt;Agent artifacts are provided as a sidecar container. This allows you to decouple the agent from the application and run it separately. It’s good for agents that monitor file systems and send results somewhere (for example, log analysis). This is particularly useful in scenarios where we have 2 separate processes running that need to communicate. In the Java world this is a rare situation because most Java agents come as jars that need to be loaded into the JVM’s classpath. The biggest downside to this is that we need to run 2 containers all the time. So if our secondary container provides just a static binary/file, we are wasting additional resources and making OpenShift’s scheduler work harder.&lt;/li&gt;
  &lt;li&gt;Init Containers (my favorite one, and the “right one” in my humble opinion). We have a main application container that contains only application code on top of a runtime (and maybe even without a runtime!). Anything else, such as the agent binaries, are delivered by an Init Container. It allows us to have separate life-cycle management for both our application and the agent binary.
For the following example, you can find all the code and templates in 
&lt;a href=&quot;https://github.com/mjudeikis/ocp-app-agent-example&quot;&gt;git repository&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Extending the Base Image&lt;/h3&gt;

&lt;p&gt;In this image, the agent is part of the container in the same pod:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/tomcat.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As this scenario is commonly known and understood, I won’t describe all the steps for deploying the New Relic agent, but I will demonstrate this scenario with a really simple example.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I would definitely recommend using base images from trusted and certified parties, like Red Hat. If you are not in the image building business yourself, you will save yourself trouble over the long term.&lt;/p&gt;

&lt;p&gt;We will use &lt;a href=&quot;https://access.redhat.com/containers/#/registry.access.redhat.com/jboss-webserver-3/webserver30-tomcat7-openshift&quot;&gt;JBoss Web Server 3.0&lt;/a&gt;, (Red Hat’s supported distribution of Tomcat) image as our base. We will also use OpenShift builds that take the base image from current namespace/project and add layers on top producing a new image as a result. In this example, we’re embedding the Dockerfile in the BuildConfig definition so we can avoid using a version control repository. We can add binaries or any other required changes to the image definition and be all set.&lt;/p&gt;

&lt;p&gt;Also, we define image triggers so that the build happens automatically by the platform every time the base image is updated by the vendor — Red Hat, in this example.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
  output:
    to:
      kind: ImageStreamTag
      name: jboss-webserver30-tomcat7-jdk7-openshift:latest
  postCommit: {}
  resources: {}
  runPolicy: Serial
  source:
    dockerfile: &quot;FROM registry.access.redhat.com/jboss-webserver-3/webserver30-tomcat7-openshift\nUSER
root\nRUN echo 2 | /usr/sbin/alternatives --config java \nRUN echo 2 | /usr/sbin/alternatives
--config javac\nENV JAVA_HOME=/usr/lib/jvm/java-1.7.0 \nENV JAVA_VERSION=1.7.0
\nUSER 185&quot;
    type: Dockerfile
  strategy:
    dockerStrategy:
      from:
        kind: ImageStreamTag
        name: jboss-webserver30-tomcat7-openshift:latest
    type: Docker
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The image produced as the result of this build can be then used as a base image for all your applications, as now they will all have the changes you require.&lt;/p&gt;

&lt;p&gt;You can use this same approach to add the binaries for the New Relic agent on top of an existing image.&lt;/p&gt;

&lt;p&gt;Here is the full example: https://github.com/mjudeikis/ocp-app-agent-example/blob/master/allinone-pattern/template.yaml&lt;/p&gt;

&lt;h3&gt;Using a Sidecar Container&lt;/h3&gt;

&lt;p&gt;In this example, we’ll use the well-defined &lt;a href=&quot;http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html&quot;&gt;sidecar design pattern&lt;/a&gt; . The image below shows a pod running 2 containers that share a common area:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image11-24.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We’ll build a second container that we’ll use as a sidecar and that will run side-by-side with our main application container. (You can find the source code for this sidecar container (in the github)[https://github.com/mjudeikis/ocp-app-agent-example/tree/master/sidecar-pattern/container] ).&lt;/p&gt;

&lt;p&gt;This image just holds the agent binaries, and all required configuration will be mounted as a Secret and a ConfigMap, following guidance from the (twelve-factor)[https://12factor.net/] application development methodology.&lt;/p&gt;

&lt;p&gt;Let’s create a project for this use case:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;oc new-project sidecar-mon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We’ll build New Relic sidecar container:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;oc new-build https://github.com/mangirdaz/ocp-app-agent-example --context-dir=sidecar-pattern/container --name=newrelic-sidecar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we need to create a Secret and a ConfigMap for this agent:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#create secret for API KEY
oc create secret generic newrelic-apikey --from-literal=API_KEY=b57f9f51b1ba14b891509c42218b82f1830xxxx
#create configmap from file in sidecar-pattern/container/newrelic
oc create configmap newrelic-config --from-file=newrelic.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is an example of 2 containers running together in the same pod:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   #sidecar container, which provides agent binaries
 - image: mangirdas/newrelic-sidecar:latest
   name: newrelic
   volumeMounts:
   #shared volume space betwean 2 containers.
   - mountPath: /newrelic
     name: newrelic-volume
   #mounting agent configuration to the sidecar
   - mountPath: /newrelic-config
     name: newrelic-config
 - image: ${APPLICATION_NAME}:latest
   imagePullPolicy: Always
   name: ${APPLICATION_NAME}
   env: 
   - name: NEW_RELIC_APP_NAME
     value: ${APPLICATION_NAME}
#set API key from secret as environment variable
   - name: NEW_RELIC_LICENSE_KEY
     valueFrom:
       secretKeyRef:
         name: newrelic-apikey
         key: apikey
   - name: CATALINA_OPTS_APPEND
     value: ${CATALINA_OPTS_APPEND}
   #in New Relic case this is mandatory. Otherwise agent will log to file and running container will start growing. 
   - name: NEW_RELIC_LOG
     value: &quot;STDOUT&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The most important thing to note when using this pattern is that the sidecar container will copy files on the main container into a shared location at startup time. This is accomplished using a shared filesystem and accessible through each container’s volume mounts. This is done in the &lt;a href=&quot;https://github.com/mjudeikis/ocp-app-agent-example/blob/master/sidecar-pattern/container/sleep.sh#L2&quot;&gt;container/sleep.sh script&lt;/a&gt;.
Now that we have ConfigMaps and Secrets created, we can deploy:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;oc process -f https://raw.githubusercontent.com/mjudeikis/ocp-app-agent-example/master/sidecar-pattern/template/template.yam -p APPLICATION_NAME=example-app | oc create -f - 
#This will start build and trigger deployment too
oc start-build example-app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Below is the sidecar deployment with 2 containers in the pod:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image9-26.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The result is one single pod running with two containers. There is one for the main application and a secondary container (sidecar) providing binaries for logging using the shared filesystem (emptyDir) functionality. That one will mostly sleep.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image10-28.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Using Init Containers&lt;/h3&gt;

&lt;p&gt;Here is an init phase agent being provided to main container and moved to run phase:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image12-30.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we’ll use a similar container for the agent, providing the binaries to our main application. But in this case, the container will copy the binaries to the application container on startup and will be then destroyed as part of the pod startup life cycle. It can be compared to (pre-start hooks from Openshift V2)[https://developers.openshift.com/managing-your-applications/action-hooks.html] or (hooks from LXE advanced container usage patterns)[https://stgraber.org/2013/12/23/lxc-1-0-some-more-advanced-container-usage/].&lt;/p&gt;

&lt;p&gt;Let’s create a project for this use case:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;oc new-project init-mon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s see it in practice:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#lets build newrelic container for init phase
oc new-build https://github.com/mangirdaz/ocp-app-agent-example --context-dir=init-pattern/container/ --name=newrelic-init
#create secrets, same as in case 2
cd init-pattern/container/newrelic
oc create secret generic newrelic-apikey --from-literal=API_KEY=b57f9f51b1ba14b891509c42218b82f1830exxxx
oc create configmap newrelic-config --from-file=newrelic.yml
#create template application stack
oc process -f https://raw.githubusercontent.com/mangirdaz/ocp-app-agent-example/master/init-pattern/template/template.yaml -p APPLICATION_NAME=init-example | oc create -f -
oc start-build init-example
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this case, our deployment looks a little bit different.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Currently, Init Containers are defined in annotations, and so we use images directly from the Docker Hub. This is because we use Openshift GA 3.5, which does not yet have full Init Container integration. But from Openshift 3.6/Kubernetes 1.6 there will be a &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/init-containers/&quot;&gt;new syntax&lt;/a&gt; to declare an Init Container in the Deployment and DeploymentConfig and a standard way to deploy from ImageStreams will be supported.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image14-32.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image16-34.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, if you need to update the agent, you will just need to rebuild the Init Container image and restart the affected applications.&lt;/p&gt;

&lt;p&gt;This is a very valuable pattern for organisations who want to maintain application components separately. Some great examples of this are JDBC drivers provided by database engineering teams, agents provided by monitoring teams, and secondary run-time binaries that can be maintained independently and managed by separate teams (for example, Java and Tomcat).&lt;/p&gt;

&lt;p&gt;Below are the results for in both cases. The application data is visible in New Relic monitoring tool dashboard:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/media/augmentation/image15-36.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Conclusion:
We have seen that there are multiple ways to do things in OpenShift and Kubernetes, with no “one true way.” OpenShift is rapidly evolving and new capabilities are being delivered with each release. For each challenge there is a solution. You just have to know your options to find the solution that best suits your needs.&lt;/p&gt;

&lt;p&gt;Init Containers will give you tools to manage your applications in almost any imaginable scenario. With these tools, you’ll be able to construct the most complex and amazing application deployment patterns. Together with (StatefulSets)[https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/], Init Containers brings true power to your datacentre and enables fast and rapid development.&lt;/p&gt;

&lt;p&gt;Also, remember that these patterns can be used and abused. As you already know, &lt;strong&gt;with great power comes great responsibility&lt;/strong&gt;.&lt;/p&gt;
</description>
				<pubDate>Thu, 13 Jul 2017 00:00:00 +0100</pubDate>
				<link>/openshift/cloud/examples/2017/07/13/mon-patterns.html</link>
				<guid isPermaLink="true">/openshift/cloud/examples/2017/07/13/mon-patterns.html</guid>
			</item>
		
	</channel>
</rss>
